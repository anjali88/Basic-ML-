{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MarketRisk_GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPg9hFv/uOHktcFk2Fhcn43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjali88/Basic-ML-/blob/master/MarketRisk_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UO_3mnG1lOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "3f884625-5b0f-4d60-fc13-3f49ef9deb82"
      },
      "source": [
        "\n",
        "# https://github.com/hamaadshah/market_risk_gan_keras/blob/master/Python/market_risk.ipynb\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from six.moves import range\n",
        "\n",
        "import os\n",
        "import math\n",
        "import inspect\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn import linear_model\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import keras\n",
        "from keras import backend as bkend\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout, Flatten, convolutional, pooling, Reshape, concatenate\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras import metrics\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.utils.generic_utils import Progbar\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from plotnine import *\n",
        "import plotnine\n",
        "\n",
        "get_ipython().magic(\"matplotlib inline\")\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "importlib.reload(bkend)\n",
        "\n",
        "print(device_lib.list_local_devices())\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13527669937339327129\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 15214655053433735538\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgJMuqlS2imO",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "66594336-1482-4eb4-b5e0-465dd56b0e3a"
      },
      "source": [
        "#upload dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60fdefb5-c0f2-4536-9e57-8271cb559fec\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-60fdefb5-c0f2-4536-9e57-8271cb559fec\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data_second.xlsx to data_second.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsvYbziq123h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b5a79986-8ad1-44e8-ee88-1672cccd325b"
      },
      "source": [
        "import io\n",
        "ret_data = pd.read_excel(io.BytesIO(uploaded['data_second.xlsx']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "#print the head\n",
        "ret_data.head()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dates</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Value</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-14 08:00:00</td>\n",
              "      <td>1682.0</td>\n",
              "      <td>1679.8</td>\n",
              "      <td>1682.0</td>\n",
              "      <td>1677.6</td>\n",
              "      <td>36935376.0</td>\n",
              "      <td>21978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-14 08:01:00</td>\n",
              "      <td>1679.8</td>\n",
              "      <td>1680.8</td>\n",
              "      <td>1681.6</td>\n",
              "      <td>1678.0</td>\n",
              "      <td>28434078.0</td>\n",
              "      <td>16930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-14 08:02:00</td>\n",
              "      <td>1681.2</td>\n",
              "      <td>1679.0</td>\n",
              "      <td>1681.2</td>\n",
              "      <td>1678.0</td>\n",
              "      <td>24295556.0</td>\n",
              "      <td>14466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-14 08:03:00</td>\n",
              "      <td>1679.0</td>\n",
              "      <td>1675.6</td>\n",
              "      <td>1679.8</td>\n",
              "      <td>1675.4</td>\n",
              "      <td>19602172.0</td>\n",
              "      <td>11683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-14 08:04:00</td>\n",
              "      <td>1674.6</td>\n",
              "      <td>1676.4</td>\n",
              "      <td>1677.4</td>\n",
              "      <td>1674.6</td>\n",
              "      <td>10772108.0</td>\n",
              "      <td>6427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Dates    Open   Close    High     Low       Value  Volume\n",
              "0 2018-02-14 08:00:00  1682.0  1679.8  1682.0  1677.6  36935376.0   21978\n",
              "1 2018-02-14 08:01:00  1679.8  1680.8  1681.6  1678.0  28434078.0   16930\n",
              "2 2018-02-14 08:02:00  1681.2  1679.0  1681.2  1678.0  24295556.0   14466\n",
              "3 2018-02-14 08:03:00  1679.0  1675.6  1679.8  1675.4  19602172.0   11683\n",
              "4 2018-02-14 08:04:00  1674.6  1676.4  1677.4  1674.6  10772108.0    6427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms5bbVMB40Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse(x):\n",
        "#function for parsing data into required format\n",
        "  return datetime.strptime(x, '%Y %m %d %H')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeljX-mN7cu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ret_data.drop('Dates', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i6DzXCz8x7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "27ffa6fc-9aa7-4846-d2d6-e5fbd2ffeb8b"
      },
      "source": [
        "ret_data.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Value</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1682.0</td>\n",
              "      <td>1679.8</td>\n",
              "      <td>1682.0</td>\n",
              "      <td>1677.6</td>\n",
              "      <td>36935376.0</td>\n",
              "      <td>21978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1679.8</td>\n",
              "      <td>1680.8</td>\n",
              "      <td>1681.6</td>\n",
              "      <td>1678.0</td>\n",
              "      <td>28434078.0</td>\n",
              "      <td>16930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1681.2</td>\n",
              "      <td>1679.0</td>\n",
              "      <td>1681.2</td>\n",
              "      <td>1678.0</td>\n",
              "      <td>24295556.0</td>\n",
              "      <td>14466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1679.0</td>\n",
              "      <td>1675.6</td>\n",
              "      <td>1679.8</td>\n",
              "      <td>1675.4</td>\n",
              "      <td>19602172.0</td>\n",
              "      <td>11683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1674.6</td>\n",
              "      <td>1676.4</td>\n",
              "      <td>1677.4</td>\n",
              "      <td>1674.6</td>\n",
              "      <td>10772108.0</td>\n",
              "      <td>6427</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Open   Close    High     Low       Value  Volume\n",
              "0  1682.0  1679.8  1682.0  1677.6  36935376.0   21978\n",
              "1  1679.8  1680.8  1681.6  1678.0  28434078.0   16930\n",
              "2  1681.2  1679.0  1681.2  1678.0  24295556.0   14466\n",
              "3  1679.0  1675.6  1679.8  1675.4  19602172.0   11683\n",
              "4  1674.6  1676.4  1677.4  1674.6  10772108.0    6427"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7zn2qFk71xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ret_data.drop('year', axis=1, inplace=True)\n",
        "ret_data.drop('month', axis=1, inplace=True)\n",
        "ret_data.drop('day', axis=1, inplace=True)\n",
        "ret_data.drop('hour', axis=1, inplace=True)\n",
        "ret_data.drop('No', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA4tiwH23qh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean = ret_data.apply(func=np.mean, axis=0)\n",
        "ret_data -= mean\n",
        "std = ret_data.apply(func=np.std, axis=0)\n",
        "ret_data /= std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0c9ae8c1-3b26-400b-810b-fe66334b45e7",
        "id": "6lekoF8wAPxK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "class BiGAN(BaseEstimator,\n",
        "            TransformerMixin):\n",
        "    def __init__(self,\n",
        "                 z_size=None,\n",
        "                 iterations=None,\n",
        "                 batch_size=None):\n",
        "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
        "        values.pop(\"self\")\n",
        "        \n",
        "        for arg, val in values.items():\n",
        "            setattr(self, arg, val)\n",
        "            # Build the discriminator.\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(optimizer=RMSprop(lr=0.0002, \n",
        "                                                     clipvalue=1.0,\n",
        "                                                     decay=1e-8),\n",
        "                                   loss=\"binary_crossentropy\",\n",
        "                                   metrics=[\"accuracy\"])\n",
        "\n",
        "        # Build the generator to fool the discriminator.\n",
        "        # Freeze the discriminator here.\n",
        "        self.discriminator.trainable = False\n",
        "        self.generator = self.build_generator()\n",
        "        self.encoder = self.build_encoder()\n",
        "        \n",
        "        noise = Input(shape=(self.z_size, ))\n",
        "        generated_data = self.generator(noise)\n",
        "        fake = self.discriminator([noise, generated_data])\n",
        "\n",
        "        real_data = Input(shape=(5,))\n",
        "        encoding = self.encoder(real_data)\n",
        "        valid = self.discriminator([encoding, real_data])\n",
        "\n",
        "        # Set up and compile the combined model.\n",
        "        # Trains generator to fool the discriminator.\n",
        "        self.bigan_generator = Model([noise, real_data], [fake, valid])\n",
        "        self.bigan_generator.compile(loss=[\"binary_crossentropy\", \"binary_crossentropy\"],\n",
        "                                     optimizer=RMSprop(lr=0.0004, \n",
        "                                                       clipvalue=1.0,\n",
        "                                                       decay=1e-8))\n",
        "        def fit(self,\n",
        "            X,\n",
        "            y=None):\n",
        "         num_train = X.shape[0]\n",
        "         start = 0\n",
        "        \n",
        "        # Adversarial ground truths.\n",
        "        valid = np.ones((self.batch_size, 1)) \n",
        "        fake = np.zeros((self.batch_size, 1))      \n",
        "        for step in range(self.iterations):\n",
        "            # Generate a new batch of noise...\n",
        "            noise = np.random.uniform(low=-1.0, high=1.0, size=(self.batch_size, self.z_size))\n",
        "            # ...and generate a batch of synthetic returns data.\n",
        "            generated_data = self.generator.predict(noise)\n",
        "            \n",
        "            # Get a batch of real returns data...\n",
        "            stop = start + self.batch_size\n",
        "            real_batch = X[start:stop]\n",
        "            # ...and encode them.\n",
        "            encoding = self.encoder.predict(real_batch)\n",
        "\n",
        "            # Train the discriminator.\n",
        "            d_loss_real = self.discriminator.train_on_batch([encoding, real_batch], valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch([noise, generated_data], fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # Train the generator.\n",
        "            g_loss = self.bigan_generator.train_on_batch([noise, real_batch], [valid, fake])\n",
        "            \n",
        "            start += self.batch_size\n",
        "            if start > num_train - self.batch_size:\n",
        "                start = 0\n",
        "            \n",
        "            if step % 100 == 0:\n",
        "                # Plot the progress.\n",
        "                print(\"[Discriminator loss: %f, Discriminator accuracy: %.2f%%] [Generator loss: %f]\" % (d_loss[0], 100 * d_loss[1], g_loss[0]))\n",
        "                return self\n",
        "\n",
        "    def transform(self,\n",
        "                  X):\n",
        "        return self.feature_extractor.predict(X)\n",
        "\n",
        "    def build_encoder(self):\n",
        "        encoder_input = Input(shape=(5,))\n",
        "\n",
        "        encoder_model = Dense(units=100)(encoder_input)\n",
        "        encoder_model = LeakyReLU(alpha=0.2)(encoder_model)\n",
        "        encoder_model = BatchNormalization()(encoder_model)\n",
        "        encoder_model = Dense(units=100)(encoder_model)\n",
        "        encoder_model = LeakyReLU(alpha=0.2)(encoder_model)\n",
        "        \n",
        "        encoder_output = Dense(units=self.z_size, activation=\"tanh\")(encoder_model)\n",
        "        \n",
        "        self.feature_extractor = Model(encoder_input, encoder_output)\n",
        "        \n",
        "        return Model(encoder_input, encoder_output)\n",
        "        \n",
        "    def build_generator(self):\n",
        "        # We will map z, a latent vector, to continuous returns data space (..., 5).\n",
        "        latent = Input(shape=(self.z_size,))\n",
        "\n",
        "        # This produces a (..., 100) shaped tensor.\n",
        "        generator_model = Dense(units=100, activation=\"elu\")(latent)\n",
        "        generator_model = BatchNormalization()(generator_model)\n",
        "        generator_model = Dense(units=100, activation=\"elu\")(generator_model)\n",
        "        generator_model = BatchNormalization()(generator_model)\n",
        "\n",
        "        generator_output = Dense(units=5, activation=\"linear\")(generator_model)\n",
        "        \n",
        "        return Model(latent, generator_output)\n",
        "    \n",
        "    def build_discriminator(self):\n",
        "        z = Input(shape=(self.z_size,))\n",
        "        ret_data = Input(shape=(5,))\n",
        "        discriminator_inputs = concatenate([z, ret_data], axis=1)\n",
        "\n",
        "        discriminator_model = Dense(units=100)(discriminator_inputs)\n",
        "        discriminator_model = LeakyReLU(alpha=0.2)(discriminator_model)\n",
        "        discriminator_model = Dropout(rate=0.5)(discriminator_model)\n",
        "        discriminator_output = Dense(units=1, activation=\"sigmoid\")(discriminator_model)\n",
        "        \n",
        "        return Model([z, ret_data], discriminator_output)\n",
        "\n",
        "z_size = 10\n",
        "bigan = BiGAN(z_size=z_size,\n",
        "              batch_size=100,\n",
        "              iterations=10000)\n",
        "\n",
        "bigan.fit(X=ret_data)\n",
        "\n",
        "n_sim = 1000\n",
        "noise = np.random.uniform(low=-1.0, high=1.0, size=(n_sim, z_size))\n",
        "x = np.zeros(shape=(n_sim, 5))\n",
        "x_mean = np.zeros(shape=n_sim)\n",
        "for i, xi in enumerate(noise):\n",
        "    x[i, :] = (bigan.generator.predict(x=np.array([xi]))[0] * std) + mean\n",
        "    x_mean[i] = np.average(a=x[i, :])\n",
        "\n",
        "act_mean = np.zeros(shape=ret_data.shape[0])\n",
        "for i in range(ret_data.shape[0]):\n",
        "    act_mean[i] = np.average(a=(ret_data.iloc[i] * std) + mean)\n",
        "    \n",
        "plotnine.options.figure_size = (12, 9)\n",
        "plot = ggplot(pd.melt(pd.concat([pd.DataFrame(x_mean, columns=[\"BiGAN Portfolio Returns Distribution\"]).reset_index(drop=True),\n",
        "                                 pd.DataFrame(act_mean, columns=[\"Actual Portfolio Returns Distribution\"]).reset_index(drop=True)],\n",
        "                                axis=1))) + \\\n",
        "geom_density(aes(x=\"value\",\n",
        "                 fill=\"factor(variable)\"), \n",
        "             alpha=0.5,\n",
        "             color=\"black\") + \\\n",
        "geom_point(aes(x=\"value\",\n",
        "               y=0,\n",
        "               fill=\"factor(variable)\"), \n",
        "           alpha=0.5, \n",
        "           color=\"black\") + \\\n",
        "xlab(\"Portfolio returns\") + \\\n",
        "ylab(\"Density\") + \\\n",
        "ggtitle(\"Trained Bidirectional Generative Adversarial Network (BiGAN) Portfolio Returns\") + \\\n",
        "theme_matplotlib()\n",
        "plot.save(filename=\"trained_bigan_sampler.png\")\n",
        "\n",
        "untrained_bigan = BiGAN(z_size=z_size,\n",
        "                        batch_size=100,\n",
        "                        iterations=10000)\n",
        "\n",
        "untrained_x = np.zeros(shape=(n_sim, 5))\n",
        "untrained_x_mean = np.zeros(shape=n_sim)\n",
        "for i, xi in enumerate(noise):\n",
        "    untrained_x[i, :] = (untrained_bigan.generator.predict(x=np.array([xi]))[0] * std) + mean\n",
        "    untrained_x_mean[i] = np.average(a=untrained_x[i, :])\n",
        "\n",
        "plotnine.options.figure_size = (12, 9)\n",
        "plot = ggplot(pd.melt(pd.concat([pd.DataFrame(untrained_x_mean, columns=[\"BiGAN Portfolio Returns Distribution\"]).reset_index(drop=True),\n",
        "                                 pd.DataFrame(act_mean, columns=[\"Actual Portfolio Returns Distribution\"]).reset_index(drop=True)],\n",
        "                                axis=1))) + \\\n",
        "geom_density(aes(x=\"value\",\n",
        "                 fill=\"factor(variable)\"), \n",
        "             alpha=0.5,\n",
        "             color=\"black\") + \\\n",
        "geom_point(aes(x=\"value\",\n",
        "               y=0,\n",
        "               fill=\"factor(variable)\"), \n",
        "           alpha=0.5, \n",
        "           color=\"black\") + \\\n",
        "xlab(\"Portfolio returns\") + \\\n",
        "ylab(\"Density\") + \\\n",
        "ggtitle(\"Untrained Bidirectional Generative Adversarial Network (BiGAN) Portfolio Returns\") + \\\n",
        "theme_matplotlib()\n",
        "plot.save(filename=\"untrained_bigan_sampler.png\")\n",
        "\n",
        "print(\"The VaR at 1%% estimate given by the BiGAN: %.2f%%\" % (100 * np.percentile(a=x_mean, axis=0, q=1)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-ef366e35ae0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m bigan = BiGAN(z_size=z_size,\n\u001b[1;32m    126\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m               iterations=10000)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mbigan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mret_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-ef366e35ae0e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, z_size, iterations, batch_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# Get a batch of real returns data...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mreal_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# ...and encode them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'start' referenced before assignment"
          ]
        }
      ]
    }
  ]
}