{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pushpanjali_Banik_Scikit-learn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjali88/Basic-ML-/blob/master/Pushpanjali_Banik_Scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qniekiBjsmH",
        "colab_type": "code",
        "outputId": "a5a45add-97fe-4c75-d910-3feecd6697d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Excercise 1\n",
        "#Import statements\n",
        "#import scikit learn libraries when the are required to understand which specifc libraries are required\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#load classification dataset\n",
        "class_data = load_breast_cancer()\n",
        "class_X = pd.DataFrame(class_data.data, columns = class_data.feature_names)\n",
        "class_y = class_data.target\n",
        "\n",
        "#check the data has loaded successfully\n",
        "print(class_X.shape)\n",
        "print(class_y.shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(569, 30)\n",
            "(569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG16QyOBp_Jf",
        "colab_type": "code",
        "outputId": "88d651a1-72ce-4508-cfd4-0287511ad616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#load the regression dataset\n",
        "boston = load_boston()\n",
        "boston_X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
        "boston_y = boston.target\n",
        "\n",
        "##check the data has loaded successfully\n",
        "print(boston_X.shape)\n",
        "print(boston_y.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n",
            "(506,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf5AEMKXqh58",
        "colab_type": "code",
        "outputId": "d530064c-671c-48f0-aa2f-9bc5500a4066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Excercise 2 - Rescaling and Standardizing Data\n",
        "# Rescaling using MinMaxScaler, which converts data to a specified range, usually (0,1) or (-1,1)\n",
        "# many machine learning algorithms assume data is on the same scale\n",
        "#import minmaxscaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#create feature - use one feature but may pass all the features to rescaler\n",
        "feature = class_X['texture error']\n",
        "#print feature prior to rescaling\n",
        "print(\"Features prior to rescaling:\\n\")\n",
        "print(feature[0:8])\n",
        "#print the shape\n",
        "print(\"\\nFeature shape prior to reshaping:\")\n",
        "print(feature.shape)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features prior to rescaling:\n",
            "\n",
            "0    0.9053\n",
            "1    0.7339\n",
            "2    0.7869\n",
            "3    1.1560\n",
            "4    0.7813\n",
            "5    0.8902\n",
            "6    0.7732\n",
            "7    1.3770\n",
            "Name: texture error, dtype: float64\n",
            "\n",
            "Feature shape prior to reshaping:\n",
            "(569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLKZgv6SuZqE",
        "colab_type": "code",
        "outputId": "cabaf052-7d84-4f6c-adf2-c1ba92fb12eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# we used a pandas column, so data data has wrong shape for the function\n",
        "# we need a 2D tuple\n",
        "#reshape the data\n",
        "feature = feature.values.reshape(-1,1)\n",
        "\n",
        "# notice we now have a (samples,feature) tuple not just a (samples,) tuple\n",
        "print(\"\\nFeature shape after reshaping:\")\n",
        "feature.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Feature shape after reshaping:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNS67gfLvh3R",
        "colab_type": "code",
        "outputId": "d4e0fe40-c414-4026-a3ce-009c3b36eb0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#instantiate the scaler and pass in the range we want our value to be scaled within\n",
        "minmax_scale = MinMaxScaler(feature_range=(0,1))\n",
        "#Scale the feature - note the fit transform function, in the next example we will separate these steps\n",
        "scaled_feature = minmax_scale.fit_transform(feature)\n",
        "#view feautures we have rescaled\n",
        "print(\"Features after  rescaling:\\n\")\n",
        "scaled_feature[0:8]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features after  rescaling:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12046941],\n",
              "       [0.08258929],\n",
              "       [0.09430251],\n",
              "       [0.17587518],\n",
              "       [0.09306489],\n",
              "       [0.11713225],\n",
              "       [0.09127475],\n",
              "       [0.22471711]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAgBF9c-wPAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "4c12cced-8fc6-4e33-e43c-41813172346e"
      },
      "source": [
        "#standardising rescale features so that they are normally distributed. with a mean of 0 and std. deviation of 1\n",
        "#import appropriate library\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#transform all features in dataset, look at it before transformation\n",
        "mean_std = pd.DataFrame(data={'mean':class_X.mean(), 'std':class_X.std()})\n",
        "\n",
        "#call dataframe\n",
        "mean_std[0:8]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean radius</th>\n",
              "      <td>14.127292</td>\n",
              "      <td>3.524049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean texture</th>\n",
              "      <td>19.289649</td>\n",
              "      <td>4.301036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean perimeter</th>\n",
              "      <td>91.969033</td>\n",
              "      <td>24.298981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean area</th>\n",
              "      <td>654.889104</td>\n",
              "      <td>351.914129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean smoothness</th>\n",
              "      <td>0.096360</td>\n",
              "      <td>0.014064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean compactness</th>\n",
              "      <td>0.104341</td>\n",
              "      <td>0.052813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concavity</th>\n",
              "      <td>0.088799</td>\n",
              "      <td>0.079720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concave points</th>\n",
              "      <td>0.048919</td>\n",
              "      <td>0.038803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           mean         std\n",
              "mean radius           14.127292    3.524049\n",
              "mean texture          19.289649    4.301036\n",
              "mean perimeter        91.969033   24.298981\n",
              "mean area            654.889104  351.914129\n",
              "mean smoothness        0.096360    0.014064\n",
              "mean compactness       0.104341    0.052813\n",
              "mean concavity         0.088799    0.079720\n",
              "mean concave points    0.048919    0.038803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCCn6Rq_Y_zs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cb268bf-c11a-4407-ae34-4c0597fd24ba"
      },
      "source": [
        "#create scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "#fit the scaler - this calculates the min and max values of the dates\n",
        "scaler.fit(class_X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vn0EMhyZCWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e48c76f5-4126-4875-f423-0ddfeb34508d"
      },
      "source": [
        "# transform the data using the fitted scaler - this applies the transform using the fit\n",
        "standardized = scaler.transform(class_X)\n",
        "# this shows the features transformed - note that this returns an array not a dataframe\n",
        "standardized[0:8]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.09706398e+00, -2.07333501e+00,  1.26993369e+00,\n",
              "         9.84374905e-01,  1.56846633e+00,  3.28351467e+00,\n",
              "         2.65287398e+00,  2.53247522e+00,  2.21751501e+00,\n",
              "         2.25574689e+00,  2.48973393e+00, -5.65265059e-01,\n",
              "         2.83303087e+00,  2.48757756e+00, -2.14001647e-01,\n",
              "         1.31686157e+00,  7.24026158e-01,  6.60819941e-01,\n",
              "         1.14875667e+00,  9.07083081e-01,  1.88668963e+00,\n",
              "        -1.35929347e+00,  2.30360062e+00,  2.00123749e+00,\n",
              "         1.30768627e+00,  2.61666502e+00,  2.10952635e+00,\n",
              "         2.29607613e+00,  2.75062224e+00,  1.93701461e+00],\n",
              "       [ 1.82982061e+00, -3.53632408e-01,  1.68595471e+00,\n",
              "         1.90870825e+00, -8.26962447e-01, -4.87071673e-01,\n",
              "        -2.38458552e-02,  5.48144156e-01,  1.39236330e-03,\n",
              "        -8.68652457e-01,  4.99254601e-01, -8.76243603e-01,\n",
              "         2.63326966e-01,  7.42401948e-01, -6.05350847e-01,\n",
              "        -6.92926270e-01, -4.40780058e-01,  2.60162067e-01,\n",
              "        -8.05450380e-01, -9.94437403e-02,  1.80592744e+00,\n",
              "        -3.69203222e-01,  1.53512599e+00,  1.89048899e+00,\n",
              "        -3.75611957e-01, -4.30444219e-01, -1.46748968e-01,\n",
              "         1.08708430e+00, -2.43889668e-01,  2.81189987e-01],\n",
              "       [ 1.57988811e+00,  4.56186952e-01,  1.56650313e+00,\n",
              "         1.55888363e+00,  9.42210440e-01,  1.05292554e+00,\n",
              "         1.36347845e+00,  2.03723076e+00,  9.39684817e-01,\n",
              "        -3.98007910e-01,  1.22867595e+00, -7.80083377e-01,\n",
              "         8.50928301e-01,  1.18133606e+00, -2.97005012e-01,\n",
              "         8.14973504e-01,  2.13076435e-01,  1.42482747e+00,\n",
              "         2.37035535e-01,  2.93559404e-01,  1.51187025e+00,\n",
              "        -2.39743838e-02,  1.34747521e+00,  1.45628455e+00,\n",
              "         5.27407405e-01,  1.08293217e+00,  8.54973944e-01,\n",
              "         1.95500035e+00,  1.15225500e+00,  2.01391209e-01],\n",
              "       [-7.68909287e-01,  2.53732112e-01, -5.92687167e-01,\n",
              "        -7.64463792e-01,  3.28355348e+00,  3.40290899e+00,\n",
              "         1.91589718e+00,  1.45170736e+00,  2.86738293e+00,\n",
              "         4.91091929e+00,  3.26373441e-01, -1.10409044e-01,\n",
              "         2.86593405e-01, -2.88378148e-01,  6.89701660e-01,\n",
              "         2.74428041e+00,  8.19518384e-01,  1.11500701e+00,\n",
              "         4.73268037e+00,  2.04751088e+00, -2.81464464e-01,\n",
              "         1.33984094e-01, -2.49939304e-01, -5.50021228e-01,\n",
              "         3.39427470e+00,  3.89339743e+00,  1.98958826e+00,\n",
              "         2.17578601e+00,  6.04604135e+00,  4.93501034e+00],\n",
              "       [ 1.75029663e+00, -1.15181643e+00,  1.77657315e+00,\n",
              "         1.82622928e+00,  2.80371830e-01,  5.39340452e-01,\n",
              "         1.37101143e+00,  1.42849277e+00, -9.56046689e-03,\n",
              "        -5.62449981e-01,  1.27054278e+00, -7.90243702e-01,\n",
              "         1.27318941e+00,  1.19035676e+00,  1.48306716e+00,\n",
              "        -4.85198799e-02,  8.28470780e-01,  1.14420474e+00,\n",
              "        -3.61092272e-01,  4.99328134e-01,  1.29857524e+00,\n",
              "        -1.46677038e+00,  1.33853946e+00,  1.22072425e+00,\n",
              "         2.20556166e-01, -3.13394511e-01,  6.13178758e-01,\n",
              "         7.29259257e-01, -8.68352984e-01, -3.97099619e-01],\n",
              "       [-4.76374665e-01, -8.35335303e-01, -3.87148067e-01,\n",
              "        -5.05650454e-01,  2.23742148e+00,  1.24433549e+00,\n",
              "         8.66301596e-01,  8.24655646e-01,  1.00540180e+00,\n",
              "         1.89000504e+00, -2.55070294e-01, -5.92661652e-01,\n",
              "        -3.21304185e-01, -2.89258217e-01,  1.56346702e-01,\n",
              "         4.45543649e-01,  1.60025198e-01, -6.91235537e-02,\n",
              "         1.34118807e-01,  4.86845840e-01, -1.65498247e-01,\n",
              "        -3.13836333e-01, -1.15009456e-01, -2.44320208e-01,\n",
              "         2.04851283e+00,  1.72161644e+00,  1.26324320e+00,\n",
              "         9.05887786e-01,  1.75406939e+00,  2.24180161e+00],\n",
              "       [ 1.17090767e+00,  1.60649427e-01,  1.13812505e+00,\n",
              "         1.09529491e+00, -1.23136226e-01,  8.82952423e-02,\n",
              "         3.00072399e-01,  6.46935108e-01, -6.43246179e-02,\n",
              "        -7.62332153e-01,  1.49883071e-01, -8.04939888e-01,\n",
              "         1.55410293e-01,  2.98627465e-01, -9.09029826e-01,\n",
              "        -6.51568010e-01, -3.10141387e-01, -2.28089026e-01,\n",
              "        -8.29666081e-01, -6.11217806e-01,  1.36898330e+00,\n",
              "         3.22882892e-01,  1.36832530e+00,  1.27521954e+00,\n",
              "         5.18640227e-01,  2.12149800e-02,  5.09552250e-01,\n",
              "         1.19671580e+00,  2.62475664e-01, -1.47304787e-02],\n",
              "       [-1.18516778e-01,  3.58450132e-01, -7.28668396e-02,\n",
              "        -2.18964911e-01,  1.60404905e+00,  1.14010235e+00,\n",
              "         6.10257495e-02,  2.81950258e-01,  1.40335463e+00,\n",
              "         1.66035318e+00,  6.43623001e-01,  2.90560957e-01,\n",
              "         4.90050986e-01,  2.33722421e-01,  5.88030871e-01,\n",
              "         2.68932704e-01, -2.32553954e-01,  4.35348506e-01,\n",
              "        -6.88004232e-01,  6.11668783e-01,  1.63762976e-01,\n",
              "         4.01047912e-01,  9.94485804e-02,  2.88594274e-02,\n",
              "         1.44796112e+00,  7.24785507e-01, -2.10538519e-02,\n",
              "         6.24195735e-01,  4.77640485e-01,  1.72643451e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9BZb-9tZI0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "aa516b4c-8b64-47f1-b691-981114017cab"
      },
      "source": [
        "#have another look at the transformed data\n",
        "mean_std_transformed = pd.DataFrame(data={'mean':standardized.mean(), 'std':standardized.std()}, index=class_X.columns)\n",
        "\n",
        "# call the dataframe\n",
        "mean_std_transformed[0:8]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean radius</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean texture</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean perimeter</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean area</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean smoothness</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean compactness</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concavity</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concave points</th>\n",
              "      <td>-6.118909e-16</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             mean  std\n",
              "mean radius         -6.118909e-16  1.0\n",
              "mean texture        -6.118909e-16  1.0\n",
              "mean perimeter      -6.118909e-16  1.0\n",
              "mean area           -6.118909e-16  1.0\n",
              "mean smoothness     -6.118909e-16  1.0\n",
              "mean compactness    -6.118909e-16  1.0\n",
              "mean concavity      -6.118909e-16  1.0\n",
              "mean concave points -6.118909e-16  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLrEiyw0ZMxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9148fe5b-25b4-4edc-a601-8bfa337e36ea"
      },
      "source": [
        "#Excercise 2 - Rescaling and Standardization\n",
        "load_boston()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
              " 'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
              "         4.9800e+00],\n",
              "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
              "         9.1400e+00],\n",
              "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
              "         4.0300e+00],\n",
              "        ...,\n",
              "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         5.6400e+00],\n",
              "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
              "         6.4800e+00],\n",
              "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
              "         7.8800e+00]]),\n",
              " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
              "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
              " 'filename': '/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/boston_house_prices.csv',\n",
              " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
              "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
              "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
              "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
              "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
              "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
              "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
              "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
              "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
              "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
              "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
              "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
              "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
              "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
              "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
              "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
              "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
              "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
              "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
              "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
              "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
              "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
              "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
              "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
              "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
              "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
              "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
              "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
              "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
              "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
              "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
              "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
              "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
              "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
              "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
              "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
              "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
              "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
              "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
              "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
              "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
              "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
              "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
              "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
              "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
              "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEYTC20SZPEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "ab1305fe-d865-466b-828b-2432696495da"
      },
      "source": [
        "Class1 = load_boston()\n",
        "Class1_X = pd.DataFrame(Class1.data, columns = Class1.feature_names) #features\n",
        "Class1_y = Class1.target # labels\n",
        "print(Class1_X.shape)\n",
        "print(Class1_y.shape) #  check if data loaded successfully\n",
        "\n",
        "# FEATURE RESCALING\n",
        "from sklearn.preprocessing import MinMaxScaler # import required library\n",
        "#create feature - use one feature but may pass all the features to rescaler\n",
        "F1 = Class1_X['TAX']\n",
        "\n",
        "#print feature prior to rescaling\n",
        "print(\"Features prior to rescaling:\\n\")\n",
        "print(F1[0:10])\n",
        "\n",
        "#print the shape\n",
        "print(\"\\nFeature shape prior to reshaping:\")\n",
        "print(F1.shape)\n",
        "#Reshape the data into 2D tuple for the function\n",
        "F1 = F1.values.reshape(-1,1)\n",
        "print(\"\\nFeature shape after reshaping: \")\n",
        "print(F1.shape)\n",
        "F1[0:10]\n",
        "\n",
        "# instantiate the scaler and pass the feature range \n",
        "minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
        "#Scale the feature - note the fit transform function, in the next example we will separate these steps\n",
        "scaled_F1 = minmax_scale.fit_transform(F1)\n",
        "#view feautures we have rescaled\n",
        "print(\"Features after  rescaling:\\n\")\n",
        "scaled_F1[0:10]\n",
        "\n",
        "#STANDARDISING - using Standardscaler\n",
        "#standardise the features to be normally distributed. with a mean of 0 and std. deviation of 1\n",
        "from sklearn.preprocessing import StandardScaler # import appropriate library\n",
        "mean_std = pd.DataFrame(data={'mean':Class1_X.mean(), 'std':Class1_X.std()}) # transform all the features in the dataset\n",
        "mean_std[0:10] # call the dataframe\n",
        "print()\n",
        "scaler = StandardScaler() #create the standard scaler\n",
        "scaler.fit(Class1_X) #fit the scaler - this calculates the min and max values of the dates\n",
        "standardized1 = scaler.transform(Class1_X) # transform the data using the fitted scaler - this applies the transform using the fit\n",
        "standardized1[0:8]# this shows the features transformed - note that this returns an array not a dataframe\n",
        "mean_std_transformed = pd.DataFrame(data={'mean':standardized1.mean(), 'std':standardized1.std()}, index=Class1_X.columns) #have another look at the transformed data\n",
        "mean_std_transformed[0:10] # call the dataframe"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n",
            "(506,)\n",
            "Features prior to rescaling:\n",
            "\n",
            "0    296.0\n",
            "1    242.0\n",
            "2    242.0\n",
            "3    222.0\n",
            "4    222.0\n",
            "5    222.0\n",
            "6    311.0\n",
            "7    311.0\n",
            "8    311.0\n",
            "9    311.0\n",
            "Name: TAX, dtype: float64\n",
            "\n",
            "Feature shape prior to reshaping:\n",
            "(506,)\n",
            "\n",
            "Feature shape after reshaping: \n",
            "(506, 1)\n",
            "Features after  rescaling:\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>-1.114746e-15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               mean  std\n",
              "CRIM  -1.114746e-15  1.0\n",
              "ZN    -1.114746e-15  1.0\n",
              "INDUS -1.114746e-15  1.0\n",
              "CHAS  -1.114746e-15  1.0\n",
              "NOX   -1.114746e-15  1.0\n",
              "RM    -1.114746e-15  1.0\n",
              "AGE   -1.114746e-15  1.0\n",
              "DIS   -1.114746e-15  1.0\n",
              "RAD   -1.114746e-15  1.0\n",
              "TAX   -1.114746e-15  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVGfJXrgZZNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "223abecb-c104-4d3f-cffe-a6cb74f0b34e"
      },
      "source": [
        "# NORMALIZER\n",
        "# Normalize samples individually to unit norm.\n",
        "# Each sample (i.e. each row of the data matrix) with at least one non zero component is rescaled independently of other samples so that its norm (l1 or l2) equals one.\n",
        "# Scaling inputs to unit norms is a common operation for text classification or clustering for instance\n",
        "from sklearn.preprocessing import Normalizer #import appropriate library\n",
        "transformer = Normalizer().fit(Class1_X) # fit does nothing\n",
        "print(transformer)\n",
        "normalised = transformer.transform(Class1_X)\n",
        "print(normalised)\n",
        "mean_std_transformed = pd.DataFrame(data={'mean':normalised.mean(), 'std':normalised.std()}, index=Class1_X.columns) #have another look at the transformed data\n",
        "mean_std_transformed[0:10] # call the dataframe"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalizer(copy=True, norm='l2')\n",
            "[[1.26388341e-05 3.59966795e-02 4.61957387e-03 ... 3.05971776e-02\n",
            "  7.93726783e-01 9.95908132e-03]\n",
            " [5.78529889e-05 0.00000000e+00 1.49769546e-02 ... 3.77071843e-02\n",
            "  8.40785474e-01 1.93620036e-02]\n",
            " [5.85729947e-05 0.00000000e+00 1.51744622e-02 ... 3.82044450e-02\n",
            "  8.43137761e-01 8.64965806e-03]\n",
            " ...\n",
            " [1.23765824e-04 0.00000000e+00 2.43009593e-02 ... 4.27762066e-02\n",
            "  8.08470305e-01 1.14884669e-02]\n",
            " [2.24644719e-04 0.00000000e+00 2.44548909e-02 ... 4.30471676e-02\n",
            "  8.06519433e-01 1.32831260e-02]\n",
            " [9.69214289e-05 0.00000000e+00 2.43887924e-02 ... 4.29308164e-02\n",
            "  8.11392431e-01 1.61092778e-02]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>0.123567</td>\n",
              "      <td>0.248303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           mean       std\n",
              "CRIM   0.123567  0.248303\n",
              "ZN     0.123567  0.248303\n",
              "INDUS  0.123567  0.248303\n",
              "CHAS   0.123567  0.248303\n",
              "NOX    0.123567  0.248303\n",
              "RM     0.123567  0.248303\n",
              "AGE    0.123567  0.248303\n",
              "DIS    0.123567  0.248303\n",
              "RAD    0.123567  0.248303\n",
              "TAX    0.123567  0.248303"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsv_ION1Zav2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "4a6c7f2d-4886-45cb-d8d1-e32854572b42"
      },
      "source": [
        "#Model Evaluation and Metrics\n",
        "#testing and training splits\n",
        "from sklearn.model_selection import train_test_split\n",
        "# splits data into a test and training set\n",
        "# function shuffles our data before splitting (we will get both classes in both sets)\n",
        "# setting a random_state means that this shuffling will be consistent for each run\n",
        "#setting stratify=class_y tells the function to have an even number of class labels in each set\n",
        "X_train, X_test, y_train, y_test = train_test_split(class_X,class_y, test_size=0.3, random_state=1, stratify = class_y)\n",
        "\n",
        "# verify the stratifications using np.bincount\n",
        "print('Labels counts in y:', np.bincount(class_y))\n",
        "print('Percentage of class zeroes in class_y',np.round(np.bincount(class_y)[0]/len(class_y)*100))\n",
        "\n",
        "print(\"\\n\")\n",
        "print('Labels counts in y_train:', np.bincount(y_train))\n",
        "print('Percentage of class zeroes in y_train',np.round(np.bincount(y_train)[0]/len(y_train)*100))\n",
        "\n",
        "print(\"\\n\")\n",
        "print('Labels counts in y_test:', np.bincount(y_test))\n",
        "print('Percentage of class zeroes in y_test',np.round(np.bincount(y_test)[0]/len(y_test)*100))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels counts in y: [212 357]\n",
            "Percentage of class zeroes in class_y 37.0\n",
            "\n",
            "\n",
            "Labels counts in y_train: [148 250]\n",
            "Percentage of class zeroes in y_train 37.0\n",
            "\n",
            "\n",
            "Labels counts in y_test: [ 64 107]\n",
            "Percentage of class zeroes in y_test 37.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtPajTn7Zf2A",
        "colab_type": "text"
      },
      "source": [
        "Additional ways to divide data into test and training sets exist, and we cover K-fold cross validation in the Pipeline section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46H72GAoZiNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13f657d7-7c64-4fc2-f77b-6e37b96d988e"
      },
      "source": [
        "#create a basiline model to benchmark our other estimators against\n",
        "#this can be simple estimator or we can use a dummy estimator to make predictions in a random manner\n",
        "#import appropriate statement\n",
        "from sklearn.dummy import DummyClassifier\n",
        "# creates our dummy classifier and the value we pass in to the strategy\n",
        "dummy = DummyClassifier(strategy='uniform', random_state=1)\n",
        "dummy.fit(X_train,y_train) # #train the model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyClassifier(constant=None, random_state=1, strategy='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3tC7pJAZlEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b505316-55d6-455c-9105-cfd4a466ce14"
      },
      "source": [
        "#evaluate model metrics\n",
        "dummy.score(X_test, y_test) # get an accuracy score"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.47953216374269003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3yDxq4KZod3",
        "colab_type": "text"
      },
      "source": [
        "Remember that to get a score, we need to instantiate a model, fit it to the data, predict using unseen data, compare the predictions against actual data, and score the difference. This is true for classification and regression problems, and is true no matter the method used to get there.\n",
        "\n",
        "* So, in the end-to-end tutorials we split the training and test data, fitted our data to an estimator, and called the .predict method on the estimator to get our predictions, and then passed this to a scoring function (four steps)\n",
        "* In using the estimator.score() method above, we are passing in our split data and the method is then making predictions and returning the score (three steps).\n",
        "* In the cross_val_score() method used below we are effectively using one step as the method takes an estimator and our data and returns a score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLPyEdVlZuJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9cb8ed92-bdcb-4745-dc9a-3e684cc3610a"
      },
      "source": [
        "#fit a new estimator and use cross_val_score to get a score based defined metric\n",
        "#import statements\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic = LogisticRegression() # instantiate logistic regression classifier\n",
        "\n",
        "#pass estimator and data to the method. also specify the number of folds (default is 3)\n",
        "# the default scoring method is associated with the estimator we pass in\n",
        "# use scoring parameter to pass in different scoring methods. here we use recall\n",
        "cross_val_score(logistic, class_X, class_y, cv=5, scoring=\"recall\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.98611111, 0.97222222, 0.98591549, 0.95774648, 0.95774648])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtmHOziNZx5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb67dfc2-b9a2-4bcd-a63b-b07f8df2be5a"
      },
      "source": [
        "#Excercise 3\n",
        "\n",
        "#Part 1 -Implement binary classification scoring functions\n",
        "\n",
        "#Implement f1 score - also known as balanced F-score or F-measure\n",
        "# F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal. The formula for the F1 score is:\n",
        "# F1 = 2 * (precision * recall) / (precision + recall) \n",
        "#import appropriate statements\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = cross_val_score(logistic, class_X, class_y, cv=5, scoring='f1') \n",
        "print('f1')\n",
        "print(f1)\n",
        "f1macro = cross_val_score(logistic, class_X, class_y, cv=5, scoring='f1_macro') #Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
        "print('f1macro')\n",
        "print(f1macro)\n",
        "f1micro = cross_val_score(logistic, class_X, class_y, cv=5, scoring='f1_micro') #Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "print('f1micro')\n",
        "print(f1micro)\n",
        "f1weighted = cross_val_score(logistic, class_X, class_y, cv=5, scoring='f1_weighted') #Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters macro to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "print('f1weighted')\n",
        "print(f1weighted)\n",
        "\n",
        "\n",
        "##implement precision score\n",
        "#The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "#The best value is 1 and the worst value is 0.\n",
        "#import appropriate statements\n",
        "from sklearn.metrics import precision_score\n",
        "precision = cross_val_score(logistic, class_X, class_y, cv=5, scoring='precision') \n",
        "print('precision')\n",
        "print(precision)\n",
        "precisionmacro = cross_val_score(logistic, class_X, class_y, cv=5, scoring='precision_macro') #Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account\n",
        "print('precisionmacro')\n",
        "print(precisionmacro)\n",
        "precisionmicro = cross_val_score(logistic, class_X, class_y, cv=5, scoring='precision_micro') #Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "print('precisionmicro')\n",
        "print(precisionmicro)\n",
        "precisionweighted = cross_val_score(logistic, class_X, class_y, cv=5, scoring='precision_weighted') #Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters macro to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "print('precisionweighted')\n",
        "print(precisionweighted)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "f1\n",
            "[0.94666667 0.95238095 0.97902098 0.96453901 0.97142857]\n",
            "f1macro\n",
            "[0.92333333 0.9340218  0.9714382  0.95285774 0.96245847]\n",
            "f1micro\n",
            "[0.93043478 0.93913043 0.97345133 0.95575221 0.96460177]\n",
            "f1weighted\n",
            "[0.92921739 0.9386515  0.97338422 0.95585559 0.96476053]\n",
            "precision\n",
            "[0.91025641 0.93333333 0.97222222 0.97142857 0.98550725]\n",
            "precisionmacro\n",
            "[0.94161469 0.94166667 0.97391599 0.95083056 0.95866271]\n",
            "precisionmicro\n",
            "[0.93043478 0.93913043 0.97345133 0.95575221 0.96460177]\n",
            "precisionweighted\n",
            "[0.93370695 0.93956522 0.97348131 0.95611678 0.96555202]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9R4CrSAZ-Un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2\n",
        "#Assessing our model's performance with the Receiving Operating Characteristic (ROC) Curve."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGGYWIA4aDTj",
        "colab_type": "text"
      },
      "source": [
        "A useful tool when predicting the probability of a binary outcome is the Receiver Operating Characteristic curve, or ROC curve. \n",
        "It is a plot of the false positive rate (x-axis) versus the true positive rate (y-axis) for a number of different candidate threshold values between 0.0 and 1.0. Put another way, it plots the false alarm rate versus the hit rate.\n",
        "\n",
        "The true positive rate is calculated as the number of true positives divided by the sum of the number of true positives and the number of false negatives. It describes how good the model is at predicting the positive class when the actual outcome is positive.\n",
        "\n",
        "\n",
        "* *True Positive Rate* = True Positives / (True Positives + False Negatives)\n",
        "\n",
        "The true positive rate is also referred to as sensitivity.\n",
        "\n",
        "* *Sensitivity* = True Positives / (True Positives + False Negatives)\n",
        "\n",
        "The false positive rate is calculated as the number of false positives divided by the sum of the number of false positives and the number of true negatives. It is also called the false alarm rate as it summarizes how often a positive class is predicted when the actual outcome is negative.\n",
        "\n",
        "* False Positive Rate = False Positives / (False Positives + True Negatives)\n",
        "\n",
        "The false positive rate is also referred to as the inverted specificity where specificity is the total number of true negatives divided by the sum of the number of true negatives and false positives.\n",
        "\n",
        "* Specificity = True Negatives / (True Negatives + False Positives)  \n",
        "Where:            False Positive Rate = 1 - Specificity\n",
        "      \n",
        "The ROC curve is a useful tool for a few reasons:\n",
        "* The curves of different models can be compared directly in general or for different thresholds.\n",
        "* The area under the curve (AUC) can be used as a summary of the model skill.\n",
        "The shape of the curve contains a lot of information, including what we might care about most for a problem, the expected false positive rate, and the false negative rate. To make this clear: a. Smaller values on the x-axis of the plot indicate lower false positives and higher true negatives. b. Larger values on the y-axis of the plot indicate higher true positives and lower false negatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLKJG36JaKvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import roc_curve() to plot a ROC curve. \n",
        "# The function takes both the true outcomes (0,1) from the test set and the predicted probabilities for the 1 class. The function returns the false positive rates for each threshold, true positive rates for each threshold and thresholds.\n",
        "from sklearn.metrics import roc_curve \n",
        "# import roc_auc_score() to calculate AUC for ROC\n",
        "# AUC function takes both the true outcomes (0,1) from the test set and the predicted probabilities for the 1 class. It returns the AUC score between 0.0 and 1.0 for no skill and perfect skill respectively.\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic = LogisticRegression()\n",
        "#from sklearn import svm # import svm for classification\n",
        "fpr, tpr, thresholds = roc_curve(class_y, f1, pos_label=2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}